{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import loss as gloss, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs, lr, batch_size = 5, 0.5, 256\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_prob1, drop_prob2 = 0.2, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dropout(drop_prob1),  # 在第一个全连接层后添加丢弃层\n",
    "        nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dropout(drop_prob2),  # 在第二个全连接层后添加丢弃层\n",
    "        nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.1742, train acc 0.543, test acc 0.778\n",
      "epoch 2, loss 0.5919, train acc 0.779, test acc 0.827\n",
      "epoch 3, loss 0.4912, train acc 0.820, test acc 0.846\n",
      "epoch 4, loss 0.4573, train acc 0.833, test acc 0.854\n",
      "epoch 5, loss 0.4295, train acc 0.844, test acc 0.857\n",
      "epoch 6, loss 0.4056, train acc 0.853, test acc 0.862\n",
      "epoch 7, loss 0.3852, train acc 0.859, test acc 0.869\n",
      "epoch 8, loss 0.3727, train acc 0.866, test acc 0.872\n",
      "epoch 9, loss 0.3623, train acc 0.866, test acc 0.874\n",
      "epoch 10, loss 0.3536, train acc 0.871, test acc 0.873\n",
      "epoch 11, loss 0.3458, train acc 0.873, test acc 0.879\n",
      "epoch 12, loss 0.3373, train acc 0.876, test acc 0.878\n",
      "epoch 13, loss 0.3289, train acc 0.880, test acc 0.881\n",
      "epoch 14, loss 0.3195, train acc 0.882, test acc 0.884\n",
      "epoch 15, loss 0.3134, train acc 0.885, test acc 0.881\n",
      "epoch 16, loss 0.3087, train acc 0.887, test acc 0.885\n",
      "epoch 17, loss 0.3059, train acc 0.887, test acc 0.879\n",
      "epoch 18, loss 0.2982, train acc 0.890, test acc 0.885\n",
      "epoch 19, loss 0.2962, train acc 0.891, test acc 0.892\n",
      "epoch 20, loss 0.2885, train acc 0.893, test acc 0.887\n"
     ]
    }
   ],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_prob1, drop_prob2 = 0.5, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dropout(drop_prob1),  # 在第一个全连接层后添加丢弃层\n",
    "        nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dropout(drop_prob2),  # 在第二个全连接层后添加丢弃层\n",
    "        nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.1175, train acc 0.562, test acc 0.782\n",
      "epoch 2, loss 0.5947, train acc 0.777, test acc 0.831\n",
      "epoch 3, loss 0.5125, train acc 0.812, test acc 0.851\n",
      "epoch 4, loss 0.4635, train acc 0.831, test acc 0.850\n",
      "epoch 5, loss 0.4354, train acc 0.839, test acc 0.861\n",
      "epoch 6, loss 0.4186, train acc 0.847, test acc 0.857\n",
      "epoch 7, loss 0.4039, train acc 0.851, test acc 0.874\n",
      "epoch 8, loss 0.3911, train acc 0.855, test acc 0.868\n",
      "epoch 9, loss 0.3833, train acc 0.859, test acc 0.871\n",
      "epoch 10, loss 0.3744, train acc 0.863, test acc 0.870\n",
      "epoch 11, loss 0.3643, train acc 0.866, test acc 0.876\n",
      "epoch 12, loss 0.3570, train acc 0.869, test acc 0.878\n",
      "epoch 13, loss 0.3510, train acc 0.870, test acc 0.878\n",
      "epoch 14, loss 0.3468, train acc 0.872, test acc 0.880\n",
      "epoch 15, loss 0.3421, train acc 0.873, test acc 0.878\n",
      "epoch 16, loss 0.3371, train acc 0.876, test acc 0.885\n",
      "epoch 17, loss 0.3336, train acc 0.876, test acc 0.884\n",
      "epoch 18, loss 0.3284, train acc 0.878, test acc 0.883\n",
      "epoch 19, loss 0.3239, train acc 0.880, test acc 0.888\n",
      "epoch 20, loss 0.3217, train acc 0.881, test acc 0.885\n"
     ]
    }
   ],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.2567, train acc 0.521, test acc 0.753\n",
      "epoch 2, loss 0.5708, train acc 0.785, test acc 0.838\n",
      "epoch 3, loss 0.5499, train acc 0.799, test acc 0.847\n",
      "epoch 4, loss 0.4397, train acc 0.838, test acc 0.858\n",
      "epoch 5, loss 0.4046, train acc 0.851, test acc 0.861\n",
      "epoch 6, loss 0.3834, train acc 0.859, test acc 0.870\n",
      "epoch 7, loss 0.3602, train acc 0.866, test acc 0.868\n",
      "epoch 8, loss 0.3466, train acc 0.871, test acc 0.872\n",
      "epoch 9, loss 0.3300, train acc 0.878, test acc 0.874\n",
      "epoch 10, loss 0.3164, train acc 0.881, test acc 0.881\n",
      "epoch 11, loss 0.3117, train acc 0.883, test acc 0.876\n",
      "epoch 12, loss 0.2993, train acc 0.887, test acc 0.880\n",
      "epoch 13, loss 0.2923, train acc 0.891, test acc 0.882\n",
      "epoch 14, loss 0.2907, train acc 0.892, test acc 0.876\n",
      "epoch 15, loss 0.2822, train acc 0.894, test acc 0.880\n",
      "epoch 16, loss 0.2731, train acc 0.897, test acc 0.881\n",
      "epoch 17, loss 0.2659, train acc 0.899, test acc 0.883\n",
      "epoch 18, loss 0.2649, train acc 0.900, test acc 0.887\n",
      "epoch 19, loss 0.2580, train acc 0.903, test acc 0.886\n",
      "epoch 20, loss 0.2480, train acc 0.907, test acc 0.884\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 0.001 #使用权重衰减法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.2571, train acc 0.513, test acc 0.759\n",
      "epoch 2, loss 0.6109, train acc 0.768, test acc 0.808\n",
      "epoch 3, loss 0.4989, train acc 0.816, test acc 0.846\n",
      "epoch 4, loss 0.4511, train acc 0.834, test acc 0.852\n",
      "epoch 5, loss 0.4359, train acc 0.839, test acc 0.854\n",
      "epoch 6, loss 0.4126, train acc 0.848, test acc 0.847\n",
      "epoch 7, loss 0.4024, train acc 0.851, test acc 0.865\n",
      "epoch 8, loss 0.4043, train acc 0.850, test acc 0.869\n",
      "epoch 9, loss 0.3970, train acc 0.855, test acc 0.871\n",
      "epoch 10, loss 0.3818, train acc 0.859, test acc 0.860\n",
      "epoch 11, loss 0.3815, train acc 0.861, test acc 0.872\n",
      "epoch 12, loss 0.3791, train acc 0.862, test acc 0.873\n",
      "epoch 13, loss 0.3622, train acc 0.866, test acc 0.870\n",
      "epoch 14, loss 1.4021, train acc 0.748, test acc 0.337\n",
      "epoch 15, loss 1.0277, train acc 0.622, test acc 0.790\n",
      "epoch 16, loss 0.5799, train acc 0.783, test acc 0.818\n",
      "epoch 17, loss 0.4967, train acc 0.818, test acc 0.833\n",
      "epoch 18, loss 0.4901, train acc 0.820, test acc 0.846\n",
      "epoch 19, loss 0.4490, train acc 0.834, test acc 0.853\n",
      "epoch 20, loss 0.4503, train acc 0.835, test acc 0.856\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr, 'wd': wd})\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.1252, train acc 0.557, test acc 0.758\n",
      "epoch 2, loss 0.6128, train acc 0.768, test acc 0.823\n",
      "epoch 3, loss 0.5295, train acc 0.804, test acc 0.837\n",
      "epoch 4, loss 0.4880, train acc 0.820, test acc 0.840\n",
      "epoch 5, loss 0.4688, train acc 0.828, test acc 0.855\n",
      "epoch 6, loss 0.4509, train acc 0.835, test acc 0.861\n",
      "epoch 7, loss 0.4454, train acc 0.836, test acc 0.863\n",
      "epoch 8, loss 0.4359, train acc 0.840, test acc 0.861\n",
      "epoch 9, loss 0.4276, train acc 0.843, test acc 0.865\n",
      "epoch 10, loss 0.4218, train acc 0.844, test acc 0.868\n",
      "epoch 11, loss 0.4199, train acc 0.846, test acc 0.867\n",
      "epoch 12, loss 0.4148, train acc 0.848, test acc 0.856\n",
      "epoch 13, loss 0.4125, train acc 0.849, test acc 0.865\n",
      "epoch 14, loss 0.4120, train acc 0.849, test acc 0.868\n",
      "epoch 15, loss 0.4101, train acc 0.851, test acc 0.870\n",
      "epoch 16, loss 0.4085, train acc 0.849, test acc 0.869\n",
      "epoch 17, loss 0.4061, train acc 0.850, test acc 0.869\n",
      "epoch 18, loss 0.4044, train acc 0.852, test acc 0.875\n",
      "epoch 19, loss 0.4007, train acc 0.853, test acc 0.873\n",
      "epoch 20, loss 0.4014, train acc 0.853, test acc 0.863\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dropout(drop_prob1),  # 在第一个全连接层后添加丢弃层\n",
    "        nn.Dense(256, activation=\"relu\"),\n",
    "        nn.Dropout(drop_prob2),  # 在第二个全连接层后添加丢弃层\n",
    "        nn.Dense(10))\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr, 'wd': wd})\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None,\n",
    "              None, trainer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
