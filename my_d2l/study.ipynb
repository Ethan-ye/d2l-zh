{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以分别使用 Esc 和 Enter 在命令模式和编辑模式之间跳跃。现在就试试看吧！\n",
    "进入命令模式之后（此时你没有活跃单元），你可以尝试以下快捷键：\n",
    "A 会在活跃单元之上插入一个新的单元，B 会在活跃单元之下插入一个新单元。\n",
    "连续按两次 D，可以删除一个单元。\n",
    "撤销被删除的单元，按 Z。\n",
    "Y 会将当前活跃的单元变成一个代码单元。\n",
    "按住 Shift +上或下箭头可选择多个单元。在多选模式时，按住 Shift + M 可合并你的选择。\n",
    "按 F 会弹出「查找和替换」菜单。\n",
    "处于编辑模式时（在命令模式时按 Enter 会进入编辑模式），你会发现下列快捷键很有用：\n",
    "Ctrl + Home 到达单元起始位置。\n",
    "Ctrl + S 保存进度。\n",
    "如之前提到的，Ctrl + Enter 会运行你的整个单元块。\n",
    "Alt + Enter 不止会运行你的单元块，还会在下面添加一个新单元。\n",
    "Ctrl + Shift + F 打开命令面板。\n",
    "要查看键盘快捷键完整列表，可在命令模式按「H」或进入「Help > Keyboard Shortcuts」。你一定要经常看这些快捷键，因为常会添加新的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import d2lzh as d2l\n",
    "from mxnet import gluon, image, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, model_zoo, nn\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilinear_kernel(in_channels, out_channels, kernel_size):\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size),\n",
    "                      dtype='float32')\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return nd.array(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们使用一个基于ImageNet数据集预训练的ResNet-18模型来抽取图像特征，并将该网络实例记为pretrained_net。可以看到，该模型成员变量features的最后两层分别是全局最大池化层GlobalAvgPool2D和样本变平层Flatten，而output模块包含了输出用的全连接层。全卷积网络不需要使用这些层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading C:\\Users\\ye_b\\AppData\\Roaming\\mxnet\\models\\resnet18_v2-a81db45f.zip from https://apache-mxnet.s3.cn-north-1.amazonaws.com.cn/gluon/models/resnet18_v2-a81db45f.zip...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(HybridSequential(\n",
       "   (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "   (1): Activation(relu)\n",
       "   (2): GlobalAvgPool2D(size=(1, 1), stride=(1, 1), padding=(0, 0), ceil_mode=True)\n",
       "   (3): Flatten\n",
       " ), Dense(512 -> 1000, linear))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_net = model_zoo.vision.resnet18_v2(pretrained=True)\n",
    "pretrained_net.features[-4:], pretrained_net.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.HybridSequential()#512通道输出，缩小1/32\n",
    "for layer in pretrained_net.features[:-2]:#去除池化和展平层\n",
    "    net.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 21\n",
    "net.add(nn.Conv2D(num_classes, kernel_size=1),#增加1*1分类和转置卷积输出，\n",
    "        nn.Conv2DTranspose(num_classes, kernel_size=64, padding=16,strides=32))#还原大小，但是为21通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net[-1].initialize(init.Constant(bilinear_kernel(num_classes, num_classes,64)))#采用双线性插值还原\n",
    "net[-2].initialize(init=init.Xavier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size, batch_size, colormap2label = (320, 480), 32, nd.zeros(256**3)\n",
    "for i, cm in enumerate(d2l.VOC_COLORMAP):\n",
    "    colormap2label[(cm[0] * 256 + cm[1]) * 256 + cm[2]] = i\n",
    "voc_dir = d2l.download_voc_pascal(data_dir='../data')\n",
    "\n",
    "num_workers = 0 if sys.platform.startswith('win32') else 4\n",
    "train_iter = gdata.DataLoader(\n",
    "    d2l.VOCSegDataset(True, crop_size, voc_dir, colormap2label), batch_size,\n",
    "    shuffle=True, last_batch='discard', num_workers=num_workers)\n",
    "test_iter = gdata.DataLoader(\n",
    "    d2l.VOCSegDataset(False, crop_size, voc_dir, colormap2label), batch_size,\n",
    "    last_batch='discard', num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = d2l.try_all_gpus()\n",
    "loss = gloss.SoftmaxCrossEntropyLoss(axis=1)\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1,\n",
    "                                                      'wd': 1e-3})\n",
    "d2l.train(train_iter, test_iter, net, loss, trainer, ctx, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img):\n",
    "    X = test_iter._dataset.normalize_image(img)\n",
    "    X = X.transpose((2, 0, 1)).expand_dims(axis=0)\n",
    "    pred = nd.argmax(net(X.as_in_context(ctx[0])), axis=1)#将21通道转成1通道，代表该点的类别\n",
    "    return pred.reshape((pred.shape[1], pred.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2image(pred):#将预测类别映射回它们在数据集中的标注颜色，将1通道类数据变成3通道颜色数据\n",
    "    colormap = nd.array(d2l.VOC_COLORMAP, ctx=ctx[0], dtype='uint8')\n",
    "    X = pred.astype('int32')\n",
    "    return colormap[X, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = d2l.read_voc_images(is_train=False)#读取测试集样本\n",
    "n, imgs = 4, []\n",
    "for i in range(n):\n",
    "    crop_rect = (0, 0, 480, 320)\n",
    "    X = image.fixed_crop(test_images[i], *crop_rect)#裁剪测试集\n",
    "    pred = label2image(predict(X))#将预测类别映射回它们在数据集中的标注颜色\n",
    "    imgs += [X, pred, image.fixed_crop(test_labels[i], *crop_rect)]#组成图片\n",
    "d2l.show_images(imgs[::3] + imgs[1::3] + imgs[2::3], 3, n);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
